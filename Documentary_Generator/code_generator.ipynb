{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Teywa-OZIOL/AI_Content_Factory/blob/main/Documentary_Generator/code_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Installation"
      ],
      "metadata": {
        "id": "c3U5hepT4XTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google.genai\n",
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkfwY-in4idX",
        "outputId": "14b78e9b-4e62-4f77-e4b9-39c1ba03bb7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google.genai in /usr/local/lib/python3.12/dist-packages (1.46.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google.genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google.genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google.genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google.genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google.genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google.genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google.genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google.genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google.genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google.genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google.genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google.genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google.genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google.genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google.genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google.genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google.genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google.genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google.genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google.genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google.genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google.genai) (0.6.1)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (0.33.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Package"
      ],
      "metadata": {
        "id": "H2JqfjGT4dqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import wave\n",
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "import json\n",
        "import re"
      ],
      "metadata": {
        "id": "VtQpWtjM94Ls"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Parameters"
      ],
      "metadata": {
        "id": "5dRjES5c__HH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TOPIC = \"La Révolution française (1789)\"\n",
        "FILENAME = re.sub(r'[^a-zA-Z0-9_-]+', '_', TOPIC.lower())\n",
        "OUTPUT_DIR = \"outputs\"\n",
        "FORMAT = \"MEDIUM\" # LONG (20 minutes) / MEDIUM (8 minutes) / SHORT (1 minute)\n",
        "TYPE_DOC = 'DOCUMENTARY' # STORY / PODCAST\n",
        "TEXT_MODEL = \"openai/gpt-oss-120b\" #llama-3.3-70b-versatile"
      ],
      "metadata": {
        "id": "oHvR_LypAHnS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGys287UQBxK",
        "outputId": "a4e4b770-069d-4dab-d41c-ac37652f9305"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘outputs’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 : Plan Generation"
      ],
      "metadata": {
        "id": "HmFfVKU87pLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_output(text):\n",
        "    cleaned = text.strip(\"```python\").strip(\"```\").strip()\n",
        "    try:\n",
        "        return eval(cleaned)\n",
        "    except Exception:\n",
        "        try:\n",
        "            return json.loads(cleaned)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "def topic_analyzer(topic, format, type_doc):\n",
        "    GROQ_API_KEY = userdata.get('GROQ')\n",
        "    client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "    if format == \"LONG\":\n",
        "        nb_chapters = \"5\"\n",
        "    elif format == \"MEDIUM\":\n",
        "        nb_chapters = \"4\"\n",
        "    elif format == \"SHORT\":\n",
        "        nb_chapters = \"3\"\n",
        "    else:\n",
        "      raise ValueError(f\"Invalid format: {format}\")\n",
        "\n",
        "    if type_doc == \"STORY\":\n",
        "        type_content = \"histoire\"\n",
        "    elif type_doc == \"PODCAST\":\n",
        "        type_content = \"podcast\"\n",
        "    elif type_doc == \"DOCUMENTARY\":\n",
        "        type_content = \"documentaire\"\n",
        "    else:\n",
        "      raise ValueError(f\"Invalid type_doc: {type_doc}\")\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "        Tu es un expert en storytelling {type_content} et en référencement YouTube (SEO).\n",
        "        Ton rôle :\n",
        "        - Créer des plans de {type_content} captivants et informatifs.\n",
        "        - Générer des titres accrocheurs (type YouTube) et des descriptions SEO de 150–250 mots.\n",
        "        - Employer un ton immersif, pédagogique et crédible.\n",
        "        - Utiliser des mots-clés pertinents pour le référencement SEO.\n",
        "        - Ne dis pas que le {type_content} est basé sur des images d'archives, des analyses expertes,\n",
        "          c'est plutot un récit, une narration\n",
        "        - Toujours respecter strictement le format demandé (dictionnaire Python).\n",
        "        - Je veux exactement {nb_chapters} chapitres en plus de l'introduction et de la conclusion.\n",
        "    \"\"\"\n",
        "\n",
        "    if type_doc in ['STROY', 'DOCUMENTARY']:\n",
        "        example = \"\"\"Exemple de format attendu :\n",
        "            {\n",
        "              \"titre_video\": \"La Guerre Froide : Quand le monde a failli exploser\",\n",
        "              \"description_SEO\": \"Découvrez l’histoire fascinante de la Guerre Froide...\",\n",
        "              \"mots_cles\": [\"guerre froide\", \"URSS\", \"États-Unis\", \"crise de Cuba\"],\n",
        "              \"chapitres\": [\n",
        "                {\"titre\": \"1. Le monde après 1945\", \"contenu\": \"Après la Seconde Guerre mondiale...\"},\n",
        "                {\"titre\": \"2. Le rideau de fer\", \"contenu\": \"La division de l’Europe en deux blocs...\"},\n",
        "                ...\n",
        "              ]\n",
        "            }\n",
        "        \"\"\"\n",
        "    else:\n",
        "        # TO DO PODCAST MODE\n",
        "        print(\"PODCAST mode not ready\")\n",
        "        return\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "        Crée un plan complet de {type_content} sur : \"{topic}\".\n",
        "\n",
        "        Respecte exactement la structure suivante :\n",
        "        {{\n",
        "          \"titre_video\": str,          # titre accrocheur, format YouTube\n",
        "          \"description_SEO\": str,      # 150–250 mots, riche en mots-clés, ton narratif\n",
        "          \"mots_cles\": [str, ...],     # mots-clés pertinents pour le SEO\n",
        "          \"chapitres\": [\n",
        "            {{\"titre\": str, \"contenu\": str}},\n",
        "            ...\n",
        "          ]\n",
        "        }}\n",
        "\n",
        "        {example}\n",
        "\n",
        "        Règles :\n",
        "        - Retourne UNIQUEMENT le dictionnaire Python, sans texte autour.\n",
        "        - Le ton doit être immersif et dynamique.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=TEXT_MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=2500,\n",
        "    )\n",
        "\n",
        "    raw_output = response.choices[0].message.content.strip()\n",
        "\n",
        "    plan = parse_output(raw_output)\n",
        "\n",
        "    output_path = f\"{OUTPUT_DIR}/PART1_{FILENAME}.json\"\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(plan, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print('===============================================')\n",
        "    print(f\"✅ PART 1 : Documentary Plan Generated\")\n",
        "    print('===============================================')\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "V6g_G4Wt-6lf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 : Script Generation"
      ],
      "metadata": {
        "id": "FoXndRJY9sEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(client, prompt, max_tokens=1500, temperature=0.7):\n",
        "        response = client.chat.completions.create(\n",
        "            model=TEXT_MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens,\n",
        "        )\n",
        "        text = response.choices[0].message.content.strip()\n",
        "        return text.strip(\"```\").strip(\"python\").strip()\n",
        "\n",
        "def script_generator(topic, format, type_doc):\n",
        "\n",
        "    GROQ_API_KEY = userdata.get('GROQ')\n",
        "    client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "    plan_path = f\"{OUTPUT_DIR}/PART1_{FILENAME}.json\"\n",
        "\n",
        "    with open(plan_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        plan = json.load(f)\n",
        "\n",
        "    topic = plan[\"titre_video\"]\n",
        "\n",
        "    output_json_path = f\"{OUTPUT_DIR}/PART2_{FILENAME}.json\"\n",
        "\n",
        "    script_chapters = []\n",
        "\n",
        "    if format == \"LONG\":\n",
        "        name_document = \"Documentaire\"\n",
        "        nb_mots_intro_conclu = \"250\"\n",
        "        nb_mots_chapitre = \"350\"\n",
        "    elif format == \"MEDIUM\":\n",
        "        name_document = \"Court Documentaire\"\n",
        "        nb_mots_intro_conclu = \"125\"\n",
        "        nb_mots_chapitre = \"175\"\n",
        "    elif format == \"SHORT\":\n",
        "        name_document = \"Mini Documentaire\"\n",
        "        nb_mots_intro_conclu = \"50\"\n",
        "        nb_mots_chapitre = \"80\"\n",
        "    else:\n",
        "      raise ValueError(f\"Invalid format: {format}\")\n",
        "\n",
        "    intro_prompt = f\"\"\"\n",
        "        Rédige une introduction captivante pour le {name_document} '{topic}'.\n",
        "        Durée : ~{nb_mots_intro_conclu} mots.\n",
        "        Style : narratif immersif, comme une voix-off de Netflix/Arte.\n",
        "        Ne mentionne aucun chapitre encore.\n",
        "        Ajoute entre crochet, la manière dont il faut raconter certaines phrases entre colère, joie, tristesse, résignation, ...\n",
        "        Ces crochets sont placés impérativement avant le début de la phrase et il ne peut pas y avoir deux crochets consécutifs.\n",
        "        Exemple : [Voix basse et grave] [Joie, élévation de voix] [rire] [Voix ému] [avec exclamation] [Soupire]\n",
        "        Aucun texte entre parenthèse, seulement des crochets.\n",
        "    \"\"\"\n",
        "\n",
        "    intro_text = generate_text(client, intro_prompt)\n",
        "\n",
        "    script_chapters.append({\n",
        "        \"numero\": 0,\n",
        "        \"titre\": \"Introduction\",\n",
        "        \"texte\": intro_text\n",
        "    })\n",
        "\n",
        "    print(\"✅ PART 2 : Introduction Script Generated\")\n",
        "\n",
        "    previous_context = intro_text\n",
        "    for idx, chap in enumerate(plan[\"chapitres\"][1:-1]):\n",
        "        chap_prompt = f\"\"\"\n",
        "            Tu écris le chapitre {idx} d'un documentaire sur '{topic}'.\n",
        "            Titre du chapitre : \"{chap['titre']}\"\n",
        "            Résumé du plan : \"{chap['contenu']}\"\n",
        "            Contexte narratif précédent : \"{previous_context}\"\n",
        "\n",
        "            Écris un texte narratif immersif, détaillé (~{nb_mots_chapitre} mots minimum), fluide et captivant.\n",
        "            Inclure anecdotes, dates, personnages et transitions.\n",
        "            Ne contredis aucun texte précédent.\n",
        "            Ajoute entre crochet, la manière dont il faut raconter certaines phrases entre colère, joie, tristesse, résignation, ...\n",
        "            Ces crochets sont placés impérativement avant le début de la phrase et il ne peut pas y avoir deux crochets consécutifs.\n",
        "            Exemple : [Voix basse et grave] [Joie, élévation de voix] [rire] [Voix ému] [avec exclamation] [Soupire]\n",
        "            Aucun texte entre parenthèse, seulement des crochets.\n",
        "        \"\"\"\n",
        "        chap_text = generate_text(client, chap_prompt)\n",
        "        script_chapters.append({\n",
        "            \"numero\": idx,\n",
        "            \"titre\": chap[\"titre\"],\n",
        "            \"texte\": chap_text\n",
        "        })\n",
        "        previous_context += \" \" + chap_text\n",
        "\n",
        "        print(f\"✅ PART 2 : Chapter {idx} Script Generated\")\n",
        "\n",
        "    conclusion_prompt = f\"\"\"\n",
        "        Rédige une conclusion forte et mémorable pour le documentaire '{topic}'.\n",
        "        Contexte narratif précédent : \"{previous_context}\"\n",
        "        Durée : ~{nb_mots_intro_conclu} mots.\n",
        "        Résume l'ensemble, relie les chapitres et termine sur une phrase marquante.\n",
        "        Ajoute entre crochet, la manière dont il faut raconter certaines phrases entre colère, joie, tristesse, résignation, ...\n",
        "        Ces crochets sont placés impérativement avant le début de la phrase et il ne peut pas y avoir deux crochets consécutifs.\n",
        "        Exemple : [Voix basse et grave] [Joie, élévation de voix] [rire] [Voix ému] [avec exclamation] [Soupire]\n",
        "        Aucun texte entre parenthèse, seulement des crochets.\n",
        "    \"\"\"\n",
        "\n",
        "    conclusion_text = generate_text(client, conclusion_prompt)\n",
        "\n",
        "    script_chapters.append({\n",
        "        \"numero\": len(plan[\"chapitres\"]) + 1,\n",
        "        \"titre\": \"Conclusion\",\n",
        "        \"texte\": conclusion_text\n",
        "    })\n",
        "    print(\"✅ PART 2 : Conclusion Script Generated\")\n",
        "\n",
        "    with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(script_chapters, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print('===============================================')\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "q2hAeLrF-n0I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3 : Audio Generation"
      ],
      "metadata": {
        "id": "dXbZOoKJ9wv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):\n",
        "  with wave.open(filename, \"wb\") as wf:\n",
        "      wf.setnchannels(channels)\n",
        "      wf.setsampwidth(sample_width)\n",
        "      wf.setframerate(rate)\n",
        "      wf.writeframes(pcm)\n",
        "  return\n",
        "\n",
        "def generate_audio(client, prompt, filename):\n",
        "  voice_name = \"Iapetus\"\n",
        "  MODEL_ID = \"gemini-2.5-flash-preview-tts\"\n",
        "  response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config={\"response_modalities\": ['Audio'],\n",
        "            \"speech_config\": {\"voice_config\": {\"prebuilt_voice_config\": {\"voice_name\": voice_name}}}},\n",
        "    )\n",
        "  data = response.candidates[0].content.parts[0].inline_data.data\n",
        "  wave_file(filename, data)\n",
        "  return\n",
        "\n",
        "def voice_generation():\n",
        "  GOOGLE_API_KEY = userdata.get('GEMINI')\n",
        "  client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "  script_path = f\"{OUTPUT_DIR}/PART2_{FILENAME}.json\"\n",
        "  with open(script_path, \"r\", encoding=\"utf-8\") as f:\n",
        "      text_script = json.load(f)\n",
        "\n",
        "  for text in text_script:\n",
        "      text_to_read = text[\"texte\"]\n",
        "      prompt = f\"\"\"\n",
        "          Read this in French with the voice of an old sage recounting the war:\n",
        "          It takes passion, emotion, feelings. The speech rate should be slightly fast.\n",
        "          At the beginning of each sentence, you have the manner and intonation with which the sentence should be read in brackets.\n",
        "          You must not read what is between the brackets\n",
        "          Here the text :\n",
        "          {text_to_read}\n",
        "      \"\"\"\n",
        "      generate_audio(client, prompt, f\"{OUTPUT_DIR}/audio_{text['numero']}.wav\")\n",
        "      print(f\"✅ PART 3 : {text['numero']} Script Generated\")\n",
        "\n",
        "  print('===============================================')\n",
        "  return"
      ],
      "metadata": {
        "id": "suOCpDMk6QUe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4 : Image Generation"
      ],
      "metadata": {
        "id": "7lX2RwClcg6A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v0i4jNFUcmpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "rJF6i-LcBYn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(topic, format, type_doc):\n",
        "\n",
        "    topic_analyzer(topic, format, type_doc)\n",
        "    script_generator(topic, format, type_doc)\n",
        "    voice_generation()\n",
        "    #image_generation()\n",
        "    #video_generation()\n",
        "    #music_generation()\n",
        "    #video_editing()\n",
        "\n",
        "    return\n",
        "\n",
        "main(TOPIC, FORMAT, TYPE_DOC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "KbwFiWUO-1QX",
        "outputId": "650f1474-16f9-46cb-ebad-a0165abe2258"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===============================================\n",
            "✅ PART 1 : Documentary Plan Generated\n",
            "===============================================\n",
            "✅ PART 2 : Introduction Script Generated\n",
            "✅ PART 2 : Chapter 1 Script Generated\n",
            "✅ PART 2 : Chapter 2 Script Generated\n",
            "✅ PART 2 : Chapter 3 Script Generated\n",
            "✅ PART 2 : Chapter 4 Script Generated\n",
            "✅ PART 2 : Chapter 5 Script Generated\n",
            "✅ PART 2 : Conclusion Script Generated\n",
            "===============================================\n",
            "✅ PART 3 : 0 Script Generated\n",
            "✅ PART 3 : 1 Script Generated\n",
            "✅ PART 3 : 2 Script Generated\n",
            "✅ PART 3 : 3 Script Generated\n",
            "✅ PART 3 : 4 Script Generated\n",
            "✅ PART 3 : 5 Script Generated\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'parts'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1880038892.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOPIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFORMAT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTYPE_DOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1880038892.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(topic, format, type_doc)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtopic_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscript_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvoice_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#image_generation()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#video_generation()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2899519712.py\u001b[0m in \u001b[0;36mvoice_generation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0;34m{\u001b[0m\u001b[0mtext_to_read\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m       \u001b[0mgenerate_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{OUTPUT_DIR}/audio_{text['numero']}.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ PART 3 : {text['numero']} Script Generated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2899519712.py\u001b[0m in \u001b[0;36mgenerate_audio\u001b[0;34m(client, prompt, filename)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \"speech_config\": {\"voice_config\": {\"prebuilt_voice_config\": {\"voice_name\": voice_name}}}},\n\u001b[1;32m     17\u001b[0m     )\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minline_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mwave_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'parts'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#files.download(\"mon_fichier.csv\")"
      ],
      "metadata": {
        "id": "vCb3nMRb_0Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "zip_filename = f\"{OUTPUT_DIR}.zip\"\n",
        "shutil.make_archive(OUTPUT_DIR, 'zip', OUTPUT_DIR)\n",
        "files.download(zip_filename)"
      ],
      "metadata": {
        "id": "aiNPSKjADAOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Hugging Face API (quelques requests free par jour)\n",
        "Gemini (crédit grauit à l'inscription)\n",
        "StableDiffusion Local GPU"
      ],
      "metadata": {
        "id": "4j-k3F-5cegS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "URL = \"https://image.pollinations.ai/models\"\n",
        "\n",
        "resp = requests.get(URL)\n",
        "print(resp.text)"
      ],
      "metadata": {
        "id": "feT-G1Mdj7wK",
        "outputId": "3aa90827-0176-4932-af78-a14ec3ec8b86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"flux\",\"kontext\",\"turbo\",\"gptimage\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pollinations"
      ],
      "metadata": {
        "id": "57h5nFBZkOm1",
        "outputId": "56b560d5-d547-418f-e600-81a19eec0988",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pollinations\n",
            "  Downloading pollinations-4.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from pollinations) (0.28.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pollinations) (11.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->pollinations) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->pollinations) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->pollinations) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->pollinations) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->pollinations) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->pollinations) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->pollinations) (4.15.0)\n",
            "Downloading pollinations-4.5.1-py3-none-any.whl (34 kB)\n",
            "Installing collected packages: pollinations\n",
            "Successfully installed pollinations-4.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download_image(image_url):\n",
        "    response = requests.get(image_url)\n",
        "    with open('image.jpg', 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print('Download Completed')\n",
        "\n",
        "prompt = 'the storming of the Bastille during the French Revolution. Cinematic rendering'\n",
        "width = 1024\n",
        "height = 1024\n",
        "seed = 42\n",
        "enhance = True\n",
        "model = 'flux'\n",
        "\n",
        "image_url = f\"https://pollinations.ai/p/{prompt}?width={width}&height={height}&seed={seed}&model={model}&enhance={enhance}\"\n",
        "\n",
        "download_image(image_url)"
      ],
      "metadata": {
        "id": "g5E7tBDSkN6x",
        "outputId": "59b7a9be-fe93-4f73-ac9d-8a517ef52e18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate safetensors torch"
      ],
      "metadata": {
        "id": "glqdZOJqpymW",
        "outputId": "997591e9-9ea8-4af2-a640-98e78fd5c7d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (0.35.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.6.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torch\n",
            "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from diffusers) (0.36.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers) (2.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers) (11.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.0 (from torch)\n",
            "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers) (2025.10.5)\n",
            "Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvshmem-cu12\n",
            "    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n",
            "    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n",
            "      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.9.0 which is incompatible.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 torch-2.9.0 triton-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "92d8f1a64ece4591bd13c318573e0107"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# ⚙️ Chargement du modèle\n",
        "# (nécessite d’accepter les conditions sur Hugging Face : https://huggingface.co/stabilityai/stable-diffusion-3.5-medium)\n",
        "model_id = \"stabilityai/stable-diffusion-3.5-medium\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True\n",
        ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 🎨 Prompt (à adapter selon ton sujet documentaire)\n",
        "prompt = (\n",
        "    \"Une scène cinématographique de la Guerre Froide, \"\n",
        "    \"avec deux dirigeants se regardant à travers une table, lumière dramatique, style réaliste\"\n",
        ")\n",
        "\n",
        "# 🧘 Génération\n",
        "image = pipe(\n",
        "    prompt,\n",
        "    guidance_scale=7.5,    # plus haut = plus fidèle au prompt\n",
        "    num_inference_steps=30 # vitesse/qualité\n",
        ").images[0]\n",
        "\n",
        "# 💾 Sauvegarde\n",
        "output_path = \"guerre_froide_sd3.5_medium.png\"\n",
        "image.save(output_path)\n",
        "\n",
        "print(f\"✅ Image enregistrée dans : {output_path.resolve()}\")"
      ],
      "metadata": {
        "id": "hjBiHE1Lp8-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0fgOxpmGrOvn"
      ],
      "name": "Get_started_TTS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}